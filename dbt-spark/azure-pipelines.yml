trigger:
  branches:
    include:
      - main

pool: cybertron-build-pool

variables:
  tag: '$(Build.BuildId)'

stages:
  - stage: Build_and_Publish_Python_Artifact
    displayName: Build, package and publish python artifacts.
    jobs:
      - job: BuildPythonArtifact
        displayName: Build and package python artifacts.
        strategy:
          matrix:
            Python:
              python.version: '3.11'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - script: |
              python -m pip install hatch
            displayName: 'Install hatch dependencies'

          - script: |
              set -eux
              cd dbt-spark
              hatch build
            displayName: 'Build the dbt-spark adapter'

          - task: PublishPipelineArtifact@1
            displayName: 'Publish dbt-spark adapter artifacts'
            inputs:
              targetPath: '$(Build.SourcesDirectory)/dbt-spark/dist'
              artifactName: 'dbt-spark'

      - job: PublishArtifactToPypi
        displayName: Publish artifact to BagOfHolding Unclass
        dependsOn: BuildPythonArtifact
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              buildType: 'current'
              artifactName: 'dbt-spark'
              downloadPath: '$(Pipeline.Workspace)/dbt-spark/'
            displayName: 'Download dbt-spark adapter build artifact'

          - script: |
              pip install twine
              python -m twine upload -r pypi-ap --config-file /azp/pypirc/pypirc $(Pipeline.Workspace)/dbt-spark/* --verbose
            displayName: 'Publish artifact to bagofholding.cse-cst.gc.ca'