trigger:
  branches:
    include:
      - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  tag: '$(Build.BuildId)'

stages:
  - stage: Build_and_Publish_Python_Artifact
    displayName: Build, package and publish python artifacts.
    jobs:
      - job: BuildPythonArtifact
        displayName: Build and package python artifacts.
        strategy:
          matrix:
            Python:
              python.version: '3.11'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - script: |
              python -m pip install hatch
            displayName: 'Install hatch dependencies'

          - script: |
              set -eux
              cd dbt-spark
              hatch build
            displayName: 'Build the dbt-spark adapter'

          - task: PublishPipelineArtifact@1
            displayName: 'Publish dbt-spark adapter artifacts'
            inputs:
              targetPath: '$(Build.SourcesDirectory)/dbt-spark/dist'
              artifactName: 'dbt-spark'

      - job: PublishArtifactToAPAFeed
        displayName: Publish artifact to APA feed
        dependsOn: BuildPythonArtifact
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              buildType: 'current'
              artifactName: 'dbt-spark'
              downloadPath: '$(Pipeline.Workspace)'
            displayName: 'Download dbt-spark adapter build artifact'

          - task: TwineAuthenticate@1
            inputs:
              artifactFeed: Analytical Platform/analytical-platform
            displayName: 'Twine Authenticate'

          - script: |
              pip install twine
              python -m twine upload --skip-existing -r analytical-platform --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dbt-spark/*
            displayName: 'Publish artifact to analytical-platform feed'

      # - job: PublishArtifactToPypi
      #   displayName: Publish artifact to PyPI
      #   dependsOn: BuildPythonArtifact
      #   steps:
      #     - task: DownloadBuildArtifacts@0
      #       inputs:
      #         buildType: 'current'
      #         downloadType: 'specific'
      #         downloadPath: '$(Pipeline.Workspace)'
      #       displayName: 'Download build artifact'

      #     - task: TwineAuthenticate@1
      #       inputs:
      #         pythonUploadServiceConnection: cccs-pypi
      #       displayName: 'Twine Authenticate'

      #     - script: |
      #         pip install twine
      #         python -m twine upload --skip-existing -r "cccs-pypi" --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dist/* --verbose
      #       displayName: 'Publish artifact to PyPI'