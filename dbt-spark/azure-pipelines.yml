trigger:
  branches:
    include:
      - main

pool: cybertron-build-pool

variables:
  tag: '$(Build.BuildId)'
  pythonVersion: "3.10"

stages:
  - stage: Build_and_Publish_Python_Artifact
    displayName: Build, package and publish python artifacts.
    jobs:
      - job: BuildPythonArtifact
        displayName: Build and package python artifacts.
        workspace:
          clean: all

        steps:
          - script: |
              virtualenv -p python$(pythonVersion) env
              source env/bin/activate
              python -m pip install hatch
            displayName: 'Install hatch dependencies'

          - script: |
              source env/bin/activate
              set -eux
              cd dbt-spark
              hatch build
            displayName: 'Build the dbt-spark adapter'

          # - script: |
          #     # Determine the value of dev based on the branch name
          #     if [ "$(Build.SourceBranch)" == "refs/heads/cccs/main" ]; then
          #       dev=""
          #     else
          #       dev="dev"
          #     fi
          
          #     virtualenv -p python$(pythonVersion) env
          #     source env/bin/activate
          #     pip install wheel setuptools==70.1.0
          #     pip install -r requirements.txt 
          #     # Version explicitly set to 1.4.10 until we move to dbt-core 1.6.0 and above
          #     # where the version of this package will be <dbt-core-version>.<seq-build-id>
          #     # VERSION=$(python setup.py --version).${dev}$(tag)
          #     VERSION=1.4.10.${dev}$(tag)
          #     DBT_SPARK_PACKAGE_VERSION=${VERSION} python setup.py sdist bdist_wheel
          #   displayName: "Install and Build."

          - task: PublishPipelineArtifact@1
            displayName: 'Publish dbt-spark adapter artifacts'
            inputs:
              targetPath: '$(Build.SourcesDirectory)/dbt-spark/dist'
              artifactName: 'dbt-spark'

      - job: PublishArtifactToPypi
        displayName: Publish artifact to BagOfHolding Unclass
        dependsOn: BuildPythonArtifact
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              buildType: 'current'
              artifactName: 'dbt-spark'
              downloadPath: '$(Pipeline.Workspace)/dbt-spark/'
            displayName: 'Download dbt-spark adapter build artifact'

          - script: |
              virtualenv -p python$(pythonVersion) env
              source env/bin/activate
              pip install twine
              python -m twine upload -r pypi-ap --config-file /azp/pypirc/pypirc $(Pipeline.Workspace)/dbt-spark/* --verbose
            displayName: 'Publish artifact to bagofholding.cse-cst.gc.ca'