trigger:
  branches:
    include:
      - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  tag: '$(Build.BuildId)'

stages:
  - stage: Build_and_Publish_Python_Artifact
    displayName: Build, package and publish python artifacts.
    jobs:
      - job: BuildPythonArtifact
        displayName: Build and package python artifacts.
        strategy:
          matrix:
            Python:
              python.version: '3.11'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - script: |
              python -m pip install hatch
            displayName: 'Install hatch dependencies'

          - script: |
              set -eux
              cd dbt-spark
              hatch build
            displayName: 'Build the dbt-spark adapter'

          # - script: |
          #     set -eux

          #     echo '.$(tag)' >> version.txt
          #     pip install build
          #     python -m build
          #   displayName: 'Package the extension'

          # - task: CopyFiles@2
          #   inputs:
          #     targetFolder: $(Build.ArtifactStagingDirectory)
          #   displayName: 'Stage build artifact to publish'

          - task: PublishBuildArtifacts@1
            inputs:
              targetPath: 'dist/'
              artifactName: 'dbt-spark'
              publishLocation: 'pipeline'
            displayName: 'Publish build artifacts'

      # - job: PublishArtifactToAPAFeed
      #   displayName: Publish artifact to APA feed
      #   dependsOn: BuildPythonArtifact
      #   steps:
      #     - task: DownloadBuildArtifacts@0
      #       inputs:
      #         buildType: 'current'
      #         downloadType: 'specific'
      #         downloadPath: '$(Pipeline.Workspace)'
      #       displayName: 'Download build artifact'

      #     - task: TwineAuthenticate@1
      #       inputs:
      #         artifactFeed: Analytical Platform/analytical-platform
      #       displayName: 'Twine Authenticate'

      #     - script: |
      #         pip install twine
      #         python -m twine upload --skip-existing -r analytical-platform --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dist/*
      #       displayName: 'Publish artifact to analytical-platform feed'

      # - job: PublishArtifactToPypi
      #   displayName: Publish artifact to PyPI
      #   dependsOn: BuildPythonArtifact
      #   steps:
      #     - task: DownloadBuildArtifacts@0
      #       inputs:
      #         buildType: 'current'
      #         downloadType: 'specific'
      #         downloadPath: '$(Pipeline.Workspace)'
      #       displayName: 'Download build artifact'

      #     - task: TwineAuthenticate@1
      #       inputs:
      #         pythonUploadServiceConnection: cccs-pypi
      #       displayName: 'Twine Authenticate'

      #     - script: |
      #         pip install twine
      #         python -m twine upload --skip-existing -r "cccs-pypi" --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dist/* --verbose
      #       displayName: 'Publish artifact to PyPI'